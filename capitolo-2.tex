\chapter{Il problema}
in questo capitolo spiego meglio il problema, parla dei file audio che hai utilizzato wav  airff, delle features che hai estratto 

Come già illustrato il dominio del problema è il suono. Per poterne svolgere delle analisi e ricavare i dati necessari deve prima di tutto essere catturato, questo tramite microfoni collegati ad degli appositi ADC\footnote{Strumenti in grado di convertire il segnale analogico fornito da componenti analogiche, microfoni audio per questo particolare caso, in digitale. Nello specifico per il suono questi convertitori sono chiamati schede audio} che porteranno il segnale a un computer in grado, tramite appositi software, di salvare l'audio catturato in file audio WAV o AIFF, formati audio non compressi in grado di preservare tutte le informazioni catturate con la strumentazione usata, a differenza di formati come mp3\footnote{Formato audio compresso per essere di dimensioni inferiori ma di qualità inferiore rispetto ai due appena descritti.}.

\section{La discretizzazione}
Essendo dunque il suono riconvertito in digitale la sua onda non è più continua come quella catturata da un microfono, ma viene discretizzata passando in digitale. Questo significa che l'onda risultante sul computer svolgente le registrazioni sarà un insieme di punti, detti anche \emph{campioni} o \emph{samples}, distanti tra loro intervalli di tempo sufficientemente brevi e costanti, che verranno poi interpolati tra loro per ricreare quella che è l'onda sonora inizialmente catturata. Introduciamo dunque una caratteristica del suono registrato in ambiente digitale, il \emph{samplerate}(SR) (ovvero frequenza di campionamento) tipicamente pari a 44100Hz\footnote{Ovvero 44100 campioni rilevati ogni secondo}\footnote{Questa è la frequenza minima di campionamento per registrazioni che interessano lo spettro dell'udibile all'uomo 20-22KHz, ovvero $SR\ge2f_{max}$, questo per evitare la generazione di onde fantasma nei segnali registrati.}, o più fino a 192KHz.\\
Nel passare da analogico a digitale particolare attenzione deve essere prestata anche alla \emph{risoluzione} dell'onda, infinita per un segnale analogico e non per uno digitale, infatti un segnale digitale ha una risoluzione tanto maggiore tanto quanto grande il valore di \emph{bit depth}. Il segnale audio viene discretizzato non solo nel tempo, ma anche in ampiezza, e la risoluzione indica quanto quanti valori possibili può assumere in ampiezza un segnale audio digitale, tanto è maggiore la bit depth tanto più la risoluzione di un segnale digitale si avvicinerà a quella di uno analogico. Solitamente il valore di registrazione, a livello professionale, è di 24 bit, il che equivale ad avere $2^{24}$ valori possibili in ampiezza per il segnale.\\
link immagine
https://www.blackghostaudio.com/blog/sample-rate-bit-depth-explained
\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{./immagini/SR-bitdepth.jpeg}
	\end{center}
	\caption{Conversione segnale audio analogico digitale}\label{fig:SR-bitdepth}
\end{figure}


\subsection{WAV e AIFF}

\section{Features utilizzate}
%CHE DEVE ESSERE TRATTATO NEL DISCRETO, VEDI FILE AUDIO: SOTTO PUNTI WAV E AIFF


%dell'algoritmo che hai usato J48 anche se già specificato in capitolo 1,  spiega poi passaggio da NOTA NON-NOTA (problema iniziale: vedere se possibile riconoscere nota da non nota) a 5 classi(riconoscere nota a vari livelli: 100\% ... 0\%). 
%
%VEDI APPUNTI PER CAPITOLO 2/3